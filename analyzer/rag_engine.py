"""
rag_engine.py
-------------
Gemini-2.5-Flash + FAISS ê¸°ë°˜ RAG ì—”ì§„
ëª¨ë¸ë³„ marketing_reports ë²¡í„°DB + ê³µí†µ marketing_segments ë²¡í„°DBë¥¼ ë³‘í•©í•˜ì—¬
AI ê¸°ë°˜ ë§ˆì¼€íŒ… ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

import os
import json
import traceback
import threading
import time
import numpy as np
import faiss
from typing import Dict, Any, List, Tuple
import google.generativeai as genai
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer

import multiprocessing

num_cores = min(4, multiprocessing.cpu_count())  # ìµœëŒ€ 4ìŠ¤ë ˆë“œê¹Œì§€ë§Œ í—ˆìš©
os.environ["OMP_NUM_THREADS"] = str(num_cores)
os.environ["MKL_NUM_THREADS"] = str(num_cores)
os.environ["TOKENIZERS_PARALLELISM"] = "false"  # SentenceTransformer ë³‘ë ¬ í† í¬ë‚˜ì´ì € ì¤‘ë³µ ë°©ì§€

print(f"âš™ï¸ ë³‘ë ¬ ì„¤ì •: OMP={num_cores}, MKL={num_cores}")

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
print("ğŸ” GEMINI_API_KEY =", "âœ… ë¡œë“œ ì™„ë£Œ" if os.getenv("GEMINI_API_KEY") else "âŒ ì—†ìŒ")


# ------------------------------------------------
# âœ… ì„ë² ë”© ëª¨ë¸ì„ ì „ì—­ìœ¼ë¡œ 1íšŒ ë¡œë“œ (ë°±ê·¸ë¼ìš´ë“œ)
# ------------------------------------------------
embedder = None
_embedder_lock = threading.Lock()

def _load_embedder_background():
    global embedder
    try:
        with _embedder_lock:
            if embedder is None:
                print("ğŸš€ [Init] ì„ë² ë”© ëª¨ë¸ ë°±ê·¸ë¼ìš´ë“œ ë¡œë“œ ì‹œì‘...")
                t0 = time.time()
                model = SentenceTransformer("BAAI/bge-m3")
                embedder = model
                print(f"âœ… [Init] ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ì „ì—­ 1íšŒ, {time.time() - t0:.2f}s)")
    except Exception as e:
        print("âŒ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨:", e)

# ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìë™ ë¡œë“œ
threading.Thread(target=_load_embedder_background, daemon=True).start()


# ------------------------------------------------
# ë²¡í„°DB ë¡œë“œ ìœ í‹¸
# ------------------------------------------------
def load_vector_db(folder_path: str, base_name: str):
    """FAISS ì¸ë±ìŠ¤ì™€ ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
    t0 = time.time()
    index_path = os.path.join(folder_path, f"{base_name}.faiss")
    meta_path = os.path.join(folder_path, f"{base_name}_metadata.jsonl")

    if not os.path.exists(index_path) or not os.path.exists(meta_path):
        raise FileNotFoundError(f"[{base_name}] íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {folder_path}")

    index = faiss.read_index(index_path)
    with open(meta_path, "r", encoding="utf-8") as f:
        metadata = [json.loads(line.strip()) for line in f]
    print(f"â±ï¸ [load_vector_db] {base_name} ë¡œë“œ ì™„ë£Œ ({time.time() - t0:.2f}s)")
    return index, metadata


# ------------------------------------------------
# ë²¡í„° ê²€ìƒ‰
# ------------------------------------------------
def retrieve_similar_docs(index, metadata, query_vector: np.ndarray, top_k: int = 5):
    """ì¿¼ë¦¬ ë²¡í„°ë¡œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰"""
    t0 = time.time()
    D, I = index.search(query_vector, top_k)
    results = [metadata[idx] for idx in I[0] if 0 <= idx < len(metadata)]
    print(f"â±ï¸ [retrieve_similar_docs] ê²€ìƒ‰ ì™„ë£Œ ({time.time() - t0:.2f}s)")
    return results


# ------------------------------------------------
# (ê°œì„ 1) ì¿¼ë¦¬ë¬¸ êµ¬ì„±: mct_idë§Œ ì“°ì§€ ë§ê³  ì˜ë¯¸ ìˆëŠ” ë¬¸ì¥ìœ¼ë¡œ í™•ì¥
# ------------------------------------------------
def build_query_text(mct_id: str, mode: str) -> str:
    """ë§¤ì¥ì½”ë“œ ë‹¨ë… ëŒ€ì‹  ì˜ë¯¸ì  ì¿¼ë¦¬ë¬¸ìœ¼ë¡œ í™•ì¥í•˜ì—¬ ì„ë² ë”© í’ˆì§ˆ ê°œì„ """
    # ëª¨ë“œë³„ ê²€ìƒ‰ ì˜ë„ ë¬¸êµ¬ ê°€ë¯¸
    intent = {
        "v1": "ê³ ê° ë¶„ì„, êµ¬ë§¤ íŒ¨í„´, ìƒê¶Œ íŠ¹ì§•, ì±„ë„ ì„±ê³¼",
        "v2": "ì¬ë°©ë¬¸ìœ¨, ë¦¬í…ì…˜, ì˜í–¥ ìš”ì¸, ì¿ í°/ë©¤ë²„ì‹­/í‘¸ì‹œ",
        "v3": "í•µì‹¬ ë¬¸ì œì , ì›ì¸ ë¶„ì„, ë§ˆì¼€íŒ… ì•„ì´ë””ì–´, ê¸°ëŒ€íš¨ê³¼",
    }.get(mode, "ë§¤ì¥ ë¶„ì„, ë§ˆì¼€íŒ… ì „ëµ, ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸")
    return f"ë§¤ì¥ì½”ë“œ {mct_id} ê´€ë ¨ {intent} ë°ì´í„°ì™€ ìœ ì‚¬ ì‚¬ë¡€ ìš”ì•½"


# ------------------------------------------------
# (ê°œì„ 2) ë³´ê³ ì„œ-ì„¸ê·¸ë¨¼íŠ¸ ì •ë ¬: ì»¨í…ìŠ¤íŠ¸ë¥¼ ì§ì§€ì–´ ë°°ì¹˜
# ------------------------------------------------
def align_reports_with_segments(
    report_docs: List[dict], segment_docs: List[dict], max_pairs: int = 5
) -> List[Tuple[dict, dict, float]]:
    """
    ìƒìœ„ report/segment ê²°ê³¼ë¥¼ ì„ë² ë”© ì¬ê³„ì‚°ìœ¼ë¡œ ìœ ì‚¬ë„ ìŠ¤ì½”ì–´ë§ í›„ ë§¤ì¹­.
    greedyë¡œ ë†’ì€ ìœ ì‚¬ë„ë¶€í„° ì§ì„ ë§Œë“¤ì–´ ìµœëŒ€ max_pairs í˜ì–´ ë°˜í™˜.
    """
    if not report_docs or not segment_docs or embedder is None:
        return []

    # í…ìŠ¤íŠ¸ ì¶”ì¶œ
    r_texts = [r.get("text", "")[:2000] for r in report_docs]  # ê³¼ë„í•œ ê¸¸ì´ ë°©ì§€
    s_texts = [s.get("text", "")[:2000] for s in segment_docs]

    # ì„ë² ë”©
    r_emb = embedder.encode(r_texts, normalize_embeddings=True)
    s_emb = embedder.encode(s_texts, normalize_embeddings=True)

    # ìœ ì‚¬ë„ í–‰ë ¬ (cosine)
    sim = np.matmul(r_emb, s_emb.T)  # (R x S)

    pairs = []
    used_r = set()
    used_s = set()

    # greedy ë§¤ì¹­
    while len(pairs) < max_pairs:
        # ì•„ì§ ì•ˆ ì“´ indexë“¤ë§Œ ê³ ë ¤
        mask = np.full_like(sim, -1e9)
        for i in range(sim.shape[0]):
            if i in used_r: continue
            for j in range(sim.shape[1]):
                if j in used_s: continue
                mask[i, j] = sim[i, j]
        i_max, j_max = np.unravel_index(np.argmax(mask), mask.shape)
        if mask[i_max, j_max] < -1e8:
            break  # ë” ì´ìƒ ë§¤ì¹­í•  ê²Œ ì—†ìŒ
        score = float(sim[i_max, j_max])
        pairs.append((report_docs[i_max], segment_docs[j_max], score))
        used_r.add(i_max)
        used_s.add(j_max)

    return pairs


# ------------------------------------------------
# (ê°œì„ 3) í”„ë¡¬í”„íŠ¸ ì••ì¶•: ë¼ì¸ ë‹¨ìœ„ ì¤‘ë³µ ì œê±°
# ------------------------------------------------
def dedupe_lines(text: str) -> str:
    lines = text.splitlines()
    seen = set()
    out = []
    for ln in lines:
        if ln not in seen:
            seen.add(ln)
            out.append(ln)
    return "\n".join(out)


# ------------------------------------------------
# í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸° (ëª¨ë“œë³„ ë¡œì§ ë¶„ë¦¬)
# ------------------------------------------------
def get_prompt_for_mode(mode: str, mct_id: str, combined_context: str) -> str:
    """ëª¨ë“œ(v1/v2/v3)ì— ë”°ë¼ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ ë°˜í™˜"""
    prompts = {
        "v1": f"""
        ë‹¤ìŒì€ '{mct_id}' ë§¤ì¥ê³¼ ìœ ì‚¬í•œ ì‚¬ë¡€ë“¤ì˜ **ê³ ê° ë¶„ì„ ë° ë§ˆì¼€íŒ… ë°ì´í„°**ì…ë‹ˆë‹¤.
        ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **AI ë§ˆì¼€íŒ… ë¦¬í¬íŠ¸**ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

        {combined_context}

        ì‘ì„± ì§€ì¹¨:
        1ï¸âƒ£ ë§¤ì¥ í•µì‹¬ ìš”ì•½ â€” ê³ ê° êµ¬ì„±, êµ¬ë§¤ íŒ¨í„´, ì£¼ìš” ìƒê¶Œ íŠ¹ì§•ì„ ìš”ì•½  
        2ï¸âƒ£ ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ â€” ìµœì†Œ 3ê°œ, ê° ì¸ì‚¬ì´íŠ¸ë§ˆë‹¤ **ë°ì´í„° ê·¼ê±°**ë¥¼ ê´„í˜¸ë¡œ ëª…ì‹œ  
            ì˜ˆ: "10~20ëŒ€ ì—¬ì„± ê³ ê° ë¹„ì¤‘ì´ ë†’ìŒ (ì¶œì²˜: ì±”ìŠ¤*** ë¦¬í¬íŠ¸, +3.7pp)"
        3ï¸âƒ£ íƒ€ê²Ÿì¸µë³„ë¡œ ì í•©í•œ ë§ˆì¼€íŒ… ì±„ë„ ì¶”ì²œ (ì˜ˆ: ì¸ìŠ¤íƒ€ê·¸ë¨, ë„¤ì´ë²„ ë¸”ë¡œê·¸, ë°°ë‹¬ì•± ë“±)
        4ï¸âƒ£ ì¶”ì²œ ì±„ë„ë³„ ë§ì¶¤ í™ë³´ ë¬¸êµ¬ ì œì•ˆ  
        5ï¸âƒ£ ê²°ë¡  â€” ì–´ë–¤ ì±„ë„ì´ ROI ëŒ€ë¹„ ê°€ì¥ íš¨ê³¼ì ì¸ì§€ ì œì‹œ

        âš™ï¸ ì‘ì„± ê·œì¹™:
        - ëª¨ë“  ê·¼ê±°ëŠ” [ë§¤ì¥ ë¶„ì„ ë°ì´í„°] ë˜ëŠ” [ë§ˆì¼€íŒ… ì „ëµ ë°ì´í„°]ì—ì„œ ì¸ìš©í•´ì•¼ í•¨
        - ì¸ìš© ì‹œ â€œ(ì¶œì²˜: ë§¤ì¥ì½”ë“œ ë˜ëŠ” ì„¸ê·¸ë¨¼íŠ¸ëª…)â€ í˜•íƒœë¡œ í‘œì‹œ
        - ê²°ê³¼ëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±
        """,

        "v2": f"""
        ë‹¤ìŒì€ '{mct_id}' ë§¤ì¥ê³¼ ìœ ì‚¬í•œ ì‚¬ë¡€ë“¤ì˜ **ì¬ë°©ë¬¸ìœ¨ ë¶„ì„ ë°ì´í„°**ì…ë‹ˆë‹¤.
        ì´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **ì¬ë°©ë¬¸ìœ¨ í–¥ìƒ ì „ëµ ë³´ê³ ì„œ**ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

        {combined_context}

        ì‘ì„± ì§€ì¹¨:
        1ï¸âƒ£ í˜„ì¬ ì¬ë°©ë¬¸ìœ¨ ìƒíƒœ ìš”ì•½ â€” ìˆ˜ì¹˜ì™€ ë¹„êµ ê¸°ì¤€ í¬í•¨  
        2ï¸âƒ£ ì¬ë°©ë¬¸ìœ¨ì— ì˜í–¥ì„ ë¯¸ì¹œ ìš”ì¸ 3ê°€ì§€ ì´ìƒ ì œì‹œ (ê° ìš”ì¸ë³„ ë°ì´í„° ê·¼ê±° ëª…ì‹œ)
        3ï¸âƒ£ ë‹¨ê¸° / ì¤‘ê¸° / ì¥ê¸°ë³„ ë¦¬í…ì…˜ ì „ëµì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œ  
            - ë‹¨ê¸°: ì¿ í°, ì´ë²¤íŠ¸, ì•± í‘¸ì‹œ  
            - ì¤‘ê¸°: ë©¤ë²„ì‹­, ê³ ê° ì£¼ê¸° ìµœì í™”  
            - ì¥ê¸°: ì¶©ì„±ê³ ê° ê´€ë¦¬, ì»¤ë®¤ë‹ˆí‹° ê°•í™”
        4ï¸âƒ£ ê° ì „ëµì˜ ì˜ˆìƒ íš¨ê³¼ë¥¼ ìˆ˜ì¹˜ë‚˜ ì‚¬ë¡€ë¡œ ì œì‹œ  
        5ï¸âƒ£ ê²°ë¡  â€” ì–´ë–¤ ì „ëµì´ ROI ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ íš¨ìœ¨ì ì¸ì§€ ì œì‹œ

        âš™ï¸ ì‘ì„± ê·œì¹™:
        - ëª¨ë“  ê·¼ê±°ëŠ” [ë§¤ì¥ ë¶„ì„ ë°ì´í„°] ë˜ëŠ” [ë§ˆì¼€íŒ… ì „ëµ ë°ì´í„°]ì—ì„œ ì¸ìš©í•´ì•¼ í•¨
        - ì¸ìš© ì‹œ â€œ(ì¶œì²˜: ë§¤ì¥ì½”ë“œ ë˜ëŠ” ì„¸ê·¸ë¨¼íŠ¸ëª…)â€ í˜•íƒœë¡œ í‘œì‹œ
        - ê²°ê³¼ëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±
        """,

        "v3": f"""
        ë‹¤ìŒì€ '{mct_id}' ë§¤ì¥ê³¼ ìœ ì‚¬í•œ **ìš”ì‹ì—…ì¢… ê°€ë§¹ì  ë°ì´í„°**ì…ë‹ˆë‹¤.
        ì´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **í˜„ì¬ ê°€ì¥ í° ë¬¸ì œì ê³¼ ì´ë¥¼ ë³´ì™„í•  ë§ˆì¼€íŒ… ì•„ì´ë””ì–´**ë¥¼ ì œì‹œí•˜ì„¸ìš”.

        {combined_context}

        ì‘ì„± ì§€ì¹¨:
        1ï¸âƒ£ ìš”ì‹ì—…ì¢… ë§¤ì¥ì˜ í•µì‹¬ ë¬¸ì œì  3ê°œë¥¼ ë„ì¶œí•˜ê³  ê° ë¬¸ì œì˜ **ë°ì´í„° ê·¼ê±°**ë¥¼ ëª…ì‹œ  
            ì˜ˆ: "ì ì‹¬ ë§¤ì¶œ ì§‘ì¤‘ë¥  ë†’ìŒ (ì¶œì²˜: 91BA22FC44, +42%)"
        2ï¸âƒ£ ë¬¸ì œë³„ ì›ì¸ì„ ë¶„ì„í•˜ê³ , ê³ ê°êµ°/ìƒê¶Œ/íŠ¸ë Œë“œì™€ ì—°ê´€ì§€ì–´ ì„¤ëª…  
        3ï¸âƒ£ ê° ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ **ë§ˆì¼€íŒ… ì•„ì´ë””ì–´**ë¥¼ ì œì‹œ (ì˜¨ë¼ì¸/ì˜¤í”„ë¼ì¸ í¬í•¨)  
            - ì˜ˆ: ë©”ë‰´ ë¦¬ë‰´ì–¼, íƒ€ê²Ÿí˜• ê´‘ê³ , ì§€ì—­ ì œíœ´, ë°°ë‹¬ ìµœì í™” ë“±  
        4ï¸âƒ£ ê° ì•„ì´ë””ì–´ì˜ ê¸°ëŒ€ íš¨ê³¼ë¥¼ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì¶”ì •  
        5ï¸âƒ£ ê²°ë¡  â€” ì–´ë–¤ ì•„ì´ë””ì–´ê°€ ë‹¨ê¸°ì„±ê³¼ vs ì¥ê¸°ë¸Œëœë”© ì¸¡ë©´ì—ì„œ ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ì§€ ì •ë¦¬

        âš™ï¸ ì‘ì„± ê·œì¹™:
        - ë°˜ë“œì‹œ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ë…¼ë¦¬ì ìœ¼ë¡œ ì‘ì„±  
        - ì¸ìš© ì‹œ â€œ(ì¶œì²˜: ë§¤ì¥ì½”ë“œ ë˜ëŠ” ì„¸ê·¸ë¨¼íŠ¸ëª…)â€ í˜•íƒœë¡œ í‘œì‹œ  
        - ê²°ê³¼ëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±
        """,

        "default": f"""
        ë‹¤ìŒì€ '{mct_id}' ë§¤ì¥ê³¼ ìœ ì‚¬í•œ ì‚¬ë¡€ë“¤ì˜ ë°ì´í„°ì…ë‹ˆë‹¤.
        ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AI ë§ˆì¼€íŒ… ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

        {combined_context}

        ì‘ì„± ì§€ì¹¨:
        1ï¸âƒ£ ë§¤ì¥ í•µì‹¬ ìš”ì•½  
        2ï¸âƒ£ ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸  
        3ï¸âƒ£ ì£¼ìš” ë¬¸ì œì  ë° ì›ì¸  
        4ï¸âƒ£ ê°œì„  ì „ëµ  
        5ï¸âƒ£ ê²°ë¡  ë° ìš”ì•½
        """
    }
    return prompts.get(mode, prompts["default"])


# ------------------------------------------------
# RAG ë¦¬í¬íŠ¸ ìƒì„±
# ------------------------------------------------
def generate_rag_summary(mct_id: str, mode: str = "v1", top_k: int = 5) -> Dict[str, Any]:
    t_start = time.time()
    print(f"ğŸš€ [RAG Triggered] mct_id={mct_id}, mode={mode}")

    try:
        # 1ï¸âƒ£ ë²¡í„°DB ë¡œë“œ
        t0 = time.time()
        base_dir = os.path.dirname(os.path.abspath(__file__))
        report_folder = os.path.join(base_dir, "vector_dbs", mode)
        shared_folder = os.path.join(base_dir, "vector_dbs", "shared")
        reports_index, reports_meta = load_vector_db(report_folder, "marketing_reports")
        segments_index, segments_meta = load_vector_db(shared_folder, "marketing_segments")
        print(f"â±ï¸ [1] ë²¡í„°DB ë¡œë“œ ì‹œê°„: {time.time() - t0:.2f}s")

        os.environ["TOKENIZERS_PARALLELISM"] = "false"

        # 2ï¸âƒ£ ì„ë² ë”© ëª¨ë¸ í™•ì¸
        t1 = time.time()
        global embedder
        if embedder is None:
            print("âš™ï¸ ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì¤‘... (ë°±ê·¸ë¼ìš´ë“œ ë¡œë“œ ì§€ì—°)")
            _load_embedder_background()
            while embedder is None:
                time.sleep(0.5)
        print(f"â±ï¸ [2] ì„ë² ë”© ì¤€ë¹„ ì‹œê°„: {time.time() - t1:.2f}s")

        # 3ï¸âƒ£ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± (ê°œì„ : ì˜ë¯¸ ê¸°ë°˜ ì¿¼ë¦¬ë¬¸ ì‚¬ìš©)
        t2 = time.time()
        query_text = build_query_text(mct_id, mode)
        query_emb = embedder.encode([query_text], normalize_embeddings=True)
        query_vector = np.array(query_emb, dtype=np.float32)
        print(f"â±ï¸ [3] ì„ë² ë”© ìƒì„± ì‹œê°„: {time.time() - t2:.2f}s")
        print(f"ğŸ” [Query] {query_text}")

        # 4ï¸âƒ£ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
        t3 = time.time()
        report_results = retrieve_similar_docs(reports_index, reports_meta, query_vector, top_k)
        segment_results = retrieve_similar_docs(segments_index, segments_meta, query_vector, top_k)
        print(f"â±ï¸ [4] ê²€ìƒ‰ ì „ì²´ ì‹œê°„: {time.time() - t3:.2f}s")

        if not report_results and not segment_results:
            return {"error": f"'{mct_id}' ê´€ë ¨ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        # 5ï¸âƒ£ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ê°œì„ : ë³´ê³ ì„œ-ì„¸ê·¸ë¨¼íŠ¸ ì •ë ¬ + ì¤‘ë³µ ì œê±°)
        pairs = align_reports_with_segments(report_results, segment_results, max_pairs=top_k)
        if pairs:
            # í˜ì–´ ë‹¨ìœ„ë¡œ êµì°¨ ë°°ì¹˜ â†’ ëª¨ë¸ì´ ì—°ê´€ì„±ì„ ë” ì˜ í•™ìŠµ
            blocks = []
            for i, (r, s, sc) in enumerate(pairs, 1):
                r_src = r.get("source", r.get("id", "reports"))
                s_src = s.get("source", s.get("id", "segments"))
                blocks.append(
                    f"[ë§¤ì¥ ë¶„ì„ ë°ì´í„° #{i} | ì¶œì²˜: {r_src}]\n{r.get('text','')}\n\n"
                    f"[ì—°ê´€ ë§ˆì¼€íŒ… ì „ëµ ë°ì´í„° #{i} | ì¶œì²˜: {s_src} | ìœ ì‚¬ë„: {sc:.3f}]\n{s.get('text','')}\n"
                )
            combined_context = "\n\n".join(blocks)
        else:
            # í˜ì–´ë§ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
            report_context = "\n\n".join([r.get("text", "") for r in report_results])
            segment_context = "\n\n".join([r.get("text", "") for r in segment_results])
            combined_context = f"[ë§¤ì¥ ë¶„ì„ ë°ì´í„°]\n{report_context}\n\n[ë§ˆì¼€íŒ… ì „ëµ ë°ì´í„°]\n{segment_context}"

        # ë¼ì¸ ì¤‘ë³µ ì œê±°ë¡œ í”„ë¡¬í”„íŠ¸ ì••ì¶•
        before_len = len(combined_context)
        combined_context = dedupe_lines(combined_context)
        after_len = len(combined_context)
        if after_len < before_len:
            print(f"ğŸ§¹ [Context Dedupe] {before_len} â†’ {after_len} chars (-{before_len - after_len})")

        prompt = get_prompt_for_mode(mode, mct_id, combined_context)
        print(f"ğŸ§¾ [Prompt Info] ê¸€ì ìˆ˜: {len(prompt):,} / ì˜ˆìƒ í† í° ìˆ˜: ì•½ {len(prompt)//4}")

        # 6ï¸âƒ£ Gemini í˜¸ì¶œ (ì›ë³¸ ìœ ì§€)
        t4 = time.time()
        model = genai.GenerativeModel("gemini-2.5-flash")
        response = model.generate_content(prompt)
        print(f"â±ï¸ [5] Gemini í˜¸ì¶œ ì‹œê°„: {time.time() - t4:.2f}s")

        print(f"âœ… [ì´ ì†Œìš”ì‹œê°„] {time.time() - t_start:.2f}s")
        return {
            "store_code": mct_id,
            "rag_summary": response.text,
            "references": {"reports": report_results, "segments": segment_results},
        }

    except Exception as e:
        print(f"âŒ RAG ERROR: {e}")
        print(f"â±ï¸ [ì´ ì‹¤íŒ¨ê¹Œì§€ ì†Œìš”ì‹œê°„] {time.time() - t_start:.2f}s")
        return {"error": str(e), "traceback": traceback.format_exc(limit=2)}
