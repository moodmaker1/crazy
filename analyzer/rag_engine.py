"""
rag_engine.py
-------------
Gemini-2.5-Flash + FAISS ê¸°ë°˜ RAG ì—”ì§„
- ì£¼ ê³ ê°ì¸µ ê°•í™” ì „ëµ + ìœ ì‚¬ë§¤ì¥ íƒ€ê²Ÿ í™•ì¥ ì „ëµ ë³‘í•©í˜• ë¶„ì„
"""

import os
import json
import traceback
import threading
import time
import numpy as np
import faiss
from typing import Dict, Any, List, Tuple
import google.generativeai as genai
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
import multiprocessing

# ------------------------------------------------
# âœ… ë³‘ë ¬ ì„¤ì •
# ------------------------------------------------
num_cores = min(4, multiprocessing.cpu_count())
os.environ["OMP_NUM_THREADS"] = str(num_cores)
os.environ["MKL_NUM_THREADS"] = str(num_cores)
os.environ["TOKENIZERS_PARALLELISM"] = "false"
print(f"âš™ï¸ ë³‘ë ¬ ì„¤ì •: OMP={num_cores}, MKL={num_cores}")

# ------------------------------------------------
# âœ… í™˜ê²½ ë³€ìˆ˜ ë° ëª¨ë¸ ì´ˆê¸°í™”
# ------------------------------------------------
load_dotenv()
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
print("ğŸ” GEMINI_API_KEY =", "âœ… ë¡œë“œ ì™„ë£Œ" if os.getenv("GEMINI_API_KEY") else "âŒ ì—†ìŒ")

embedder = None
_embedder_lock = threading.Lock()

def _load_embedder_background():
    global embedder
    try:
        with _embedder_lock:
            if embedder is None:
                print("ğŸš€ [Init] ì„ë² ë”© ëª¨ë¸ ë°±ê·¸ë¼ìš´ë“œ ë¡œë“œ ì‹œì‘...")
                t0 = time.time()
                embedder = SentenceTransformer("BAAI/bge-m3")
                print(f"âœ… [Init] ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ì „ì—­ 1íšŒ, {time.time() - t0:.2f}s)")
    except Exception as e:
        print("âŒ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨:", e)

threading.Thread(target=_load_embedder_background, daemon=True).start()


# ------------------------------------------------
# ë²¡í„°DB ë¡œë“œ
# ------------------------------------------------
def load_vector_db(folder_path: str, base_name: str):
    t0 = time.time()
    index_path = os.path.join(folder_path, f"{base_name}.faiss")
    meta_path = os.path.join(folder_path, f"{base_name}_metadata.jsonl")
    if not os.path.exists(index_path) or not os.path.exists(meta_path):
        raise FileNotFoundError(f"[{base_name}] íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {folder_path}")
    index = faiss.read_index(index_path)
    with open(meta_path, "r", encoding="utf-8") as f:
        metadata = [json.loads(line.strip()) for line in f]
    print(f"â±ï¸ [load_vector_db] {base_name} ë¡œë“œ ì™„ë£Œ ({time.time() - t0:.2f}s)")
    return index, metadata


# ------------------------------------------------
# ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
# ------------------------------------------------
def retrieve_similar_docs(index, metadata, query_vector: np.ndarray, top_k: int = 5):
    t0 = time.time()
    D, I = index.search(query_vector, top_k)
    results = [metadata[idx] for idx in I[0] if 0 <= idx < len(metadata)]
    print(f"â±ï¸ [retrieve_similar_docs] ê²€ìƒ‰ ì™„ë£Œ ({time.time() - t0:.2f}s)")
    return results


# ------------------------------------------------
# (ê°œì„ A) ë“€ì–¼ ì¿¼ë¦¬ â€” ì£¼ ê³ ê°ì¸µ + ìœ ì‚¬ë§¤ì¥ íƒ€ê²Ÿ ê°•í™”
# ------------------------------------------------
def build_dual_queries(mct_id: str, mode: str) -> List[str]:
    """ë§¤ì¥ ì¤‘ì‹¬ ì¿¼ë¦¬ + ìœ ì‚¬ë§¤ì¥ íƒ€ê²Ÿ ì „ëµ ì¿¼ë¦¬ ë™ì‹œ ìˆ˜í–‰"""
    base_intent = {
        "v1": "ê³ ê° ë¶„ì„, ì£¼ìš” ê³ ê°ì¸µ, ìƒê¶Œ íŠ¹ì§•, ì±„ë„ ì„±ê³¼",
        "v2": "ì¬ë°©ë¬¸ìœ¨, ë¦¬í…ì…˜, ë©¤ë²„ì‹­, í‘¸ì‹œ ì „ëµ",
        "v3": "ë¬¸ì œ ì§„ë‹¨, ì›ì¸ ë¶„ì„, ê°œì„  ì•„ì´ë””ì–´",
    }.get(mode, "ë§¤ì¥ ë¶„ì„, ë§ˆì¼€íŒ… ì „ëµ, ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸")

    query_1 = f"{mct_id} ë§¤ì¥ì˜ {base_intent} ë° ì£¼ ê³ ê°ì¸µ ê°•í™” ì „ëµ"
    query_2 = (
        "ìœ ì‚¬ ë§¤ì¥ì—ì„œ ì„±ê³µí•œ ê³ ê°ì¸µ ì¬ì •ì˜ ë° ì‹ ê·œ íƒ€ê²Ÿ í™•ì¥ ì „ëµ, "
        "ì—°ë ¹ëŒ€/ì„±ë³„ë³„ íƒ€ê²ŸíŒ…, ì±„ë„ë³„ ì„±ê³¼, íŠ¸ë Œë“œ ê¸°ë°˜ ë§ˆì¼€íŒ… ì‚¬ë¡€"
    )
    return [query_1, query_2]


# ------------------------------------------------
# í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸°
# ------------------------------------------------
def get_prompt_for_mode(mode: str, mct_id: str, combined_context: str) -> str:
    """ìœ ì‚¬ë§¤ì¥ íƒ€ê²Ÿ í™•ì¥ ì§€ì‹œ ì¶”ê°€"""
    prompts = {
        "v1": f"""
        ë‹¤ìŒì€ '{mct_id}' ë§¤ì¥ê³¼ ìœ ì‚¬í•œ ì‚¬ë¡€ë“¤ì˜ ê³ ê° ë¶„ì„ ë° ë§ˆì¼€íŒ… ë°ì´í„°ì…ë‹ˆë‹¤.
        ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **AI ë§ˆì¼€íŒ… ë¦¬í¬íŠ¸**ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

        {combined_context}

        ì‘ì„± ì§€ì¹¨:
        1ï¸âƒ£ ë§¤ì¥ í•µì‹¬ ìš”ì•½ â€” ê³ ê° êµ¬ì„±, êµ¬ë§¤ íŒ¨í„´, ì£¼ìš” ìƒê¶Œ íŠ¹ì§•
        2ï¸âƒ£ ì£¼ ê³ ê°ì¸µ ê°•í™” ì „ëµ ì œì‹œ
        3ï¸âƒ£ **ìœ ì‚¬ ë§¤ì¥ì˜ ê³ ê°ì¸µ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ìƒˆë¡œìš´ íƒ€ê²Ÿ ê³ ê°ì¸µì„ ì œì‹œ**
        4ï¸âƒ£ ê° íƒ€ê²Ÿë³„ë¡œ ì í•©í•œ ë§ˆì¼€íŒ… ì±„ë„ ë° í™ë³´ ë¬¸êµ¬ë¥¼ êµ¬ì²´í™”
        """,

        "v2": f"""
        '{mct_id}' ë§¤ì¥ì˜ ì¬ë°©ë¬¸ìœ¨ ë¶„ì„ ê²°ê³¼ì™€ ìœ ì‚¬ë§¤ì¥ ì‚¬ë¡€ë¥¼ ì°¸ê³ í•´
        ì¬ë°©ë¬¸ìœ¨ í–¥ìƒ ì „ëµì„ ì œì‹œí•˜ì„¸ìš”.

        {combined_context}

        ì‘ì„± ì§€ì¹¨:
        - ë‹¨ê¸°/ì¤‘ê¸°/ì¥ê¸° ë¦¬í…ì…˜ ì „ëµ ì œì‹œ
        - ìœ ì‚¬ ë§¤ì¥ì˜ ì„±ê³µ íŒ¨í„´ì„ ì¸ìš©í•´ ì‹¤ì²œ ê°€ëŠ¥í•œ ì•„ì´ë””ì–´ ì œì‹œ
        """,

        "v3": f"""
        '{mct_id}' ë§¤ì¥ê³¼ ìœ ì‚¬í•œ ìš”ì‹ì—…ì¢… ê°€ë§¹ì  ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ
        ë¬¸ì œì ê³¼ ê°œì„  ì•„ì´ë””ì–´ë¥¼ ì œì‹œí•˜ì„¸ìš”.

        {combined_context}

        ì‘ì„± ì§€ì¹¨:
        - ë¬¸ì œ ì›ì¸ ë¶„ì„ + íŠ¸ë Œë“œ ì—°ê³„
        - ìœ ì‚¬ë§¤ì¥ì˜ ê°œì„  ì„±ê³µ ì‚¬ë¡€ë¥¼ ì°¸ê³ í•˜ì—¬ í•´ê²° ì „ëµ ì‘ì„±
        """,
    }
    return prompts.get(mode, prompts["v1"])


# ------------------------------------------------
# RAG ë¦¬í¬íŠ¸ ìƒì„±
# ------------------------------------------------
def generate_rag_summary(mct_id: str, mode: str = "v1", top_k: int = 5) -> Dict[str, Any]:
    t_start = time.time()
    print(f"ğŸš€ [RAG Triggered] mct_id={mct_id}, mode={mode}")

    try:
        base_dir = os.path.dirname(os.path.abspath(__file__))
        report_folder = os.path.join(base_dir, "vector_dbs", mode)
        shared_folder = os.path.join(base_dir, "vector_dbs", "shared")
        reports_index, reports_meta = load_vector_db(report_folder, "marketing_reports")
        segments_index, segments_meta = load_vector_db(shared_folder, "marketing_segments")

        global embedder
        if embedder is None:
            _load_embedder_background()
            while embedder is None:
                time.sleep(0.5)

        # âœ… ë“€ì–¼ ì¿¼ë¦¬ ìˆ˜í–‰ (ì£¼ ê³ ê°ì¸µ + ìœ ì‚¬ë§¤ì¥)
        queries = build_dual_queries(mct_id, mode)
        all_reports, all_segments = [], []
        for q in queries:
            q_emb = embedder.encode([q], normalize_embeddings=True)
            q_vec = np.array(q_emb, dtype=np.float32)
            all_reports.extend(retrieve_similar_docs(reports_index, reports_meta, q_vec, top_k))
            all_segments.extend(retrieve_similar_docs(segments_index, segments_meta, q_vec, top_k))

        # âœ… ì¤‘ë³µ ì œê±°
        report_results = list({
            r.get("id") or r.get("chunk_id") or r.get("store_code") or f"r{i}": r
            for i, r in enumerate(all_reports)
        }.values())
        segment_results = list({
            s.get("id") or s.get("chunk_id") or s.get("store_code") or f"s{i}": s
            for i, s in enumerate(all_segments)
        }.values())

        if not report_results and not segment_results:
            return {"error": f"'{mct_id}' ê´€ë ¨ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        # âœ… ì»¨í…ìŠ¤íŠ¸ ì„¹ì…˜ êµ¬ë¶„ (A: ë§¤ì¥, B: ìœ ì‚¬ë§¤ì¥)
        report_context = "\n\n".join([r.get("text", "") for r in report_results])
        segment_context = "\n\n".join([s.get("text", "") for s in segment_results])

        combined_context = f"""
        [ë§¤ì¥ ì£¼ìš” ë¶„ì„ ë° ê³ ê°ì¸µ ê°•í™” ë°ì´í„°]
        {report_context}

        [ìœ ì‚¬ ë§¤ì¥ íƒ€ê²Ÿ í™•ì¥ ì „ëµ ì‚¬ë¡€]
        {segment_context}
        """

        # âœ… í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = get_prompt_for_mode(mode, mct_id, combined_context)
        print(f"ğŸ§¾ [Prompt Info] ê¸€ì ìˆ˜: {len(prompt):,} / ì˜ˆìƒ í† í° ìˆ˜: {len(prompt)//4}")

        # âœ… Gemini í˜¸ì¶œ
        t4 = time.time()
        model = genai.GenerativeModel("gemini-2.5-flash")
        response = model.generate_content(prompt)
        print(f"â±ï¸ [Gemini í˜¸ì¶œ ì‹œê°„] {time.time() - t4:.2f}s")
        print(f"âœ… [ì´ ì†Œìš”ì‹œê°„] {time.time() - t_start:.2f}s")

        return {
            "store_code": mct_id,
            "rag_summary": response.text,
            "references": {"reports": report_results, "segments": segment_results},
        }

    except Exception as e:
        print(f"âŒ RAG ERROR: {e}")
        return {"error": str(e), "traceback": traceback.format_exc(limit=2)}
