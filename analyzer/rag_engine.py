"""
rag_engine.py
-------------
Gemini-2.5-Flash + FAISS ê¸°ë°˜ RAG ì—”ì§„
ëª¨ë¸ë³„ marketing_reports ë²¡í„°DB + ê³µí†µ marketing_segments ë²¡í„°DBë¥¼ ë³‘í•©í•˜ì—¬
AI ê¸°ë°˜ ë§ˆì¼€íŒ… ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

import os
import json
import traceback
import numpy as np
import faiss
from typing import Dict, Any
import google.generativeai as genai
from dotenv import load_dotenv
load_dotenv()  # .env íŒŒì¼ ë¡œë“œ

# âœ… Gemini API ì„¤ì •
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# âœ… í™˜ê²½ ë³€ìˆ˜ í™•ì¸
print("ğŸ” GEMINI_API_KEY =", os.getenv("GEMINI_API_KEY"))

# ------------------------------------------------
# ë²¡í„°DB ë¡œë“œ ìœ í‹¸
# ------------------------------------------------
def load_vector_db(folder_path: str, base_name: str):
    """FAISS ì¸ë±ìŠ¤ì™€ ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
    index_path = os.path.join(folder_path, f"{base_name}.faiss")
    meta_path = os.path.join(folder_path, f"{base_name}_metadata.jsonl")

    if not os.path.exists(index_path) or not os.path.exists(meta_path):
        raise FileNotFoundError(f"[{base_name}] íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {folder_path}")

    index = faiss.read_index(index_path)
    with open(meta_path, "r", encoding="utf-8") as f:
        metadata = [json.loads(line.strip()) for line in f]

    return index, metadata


# ------------------------------------------------
# ë²¡í„° ê²€ìƒ‰
# ------------------------------------------------
def retrieve_similar_docs(index, metadata, query_vector: np.ndarray, top_k: int = 5):
    """ì¿¼ë¦¬ ë²¡í„°ë¡œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰"""
    D, I = index.search(query_vector, top_k)
    results = []
    for idx in I[0]:
        if 0 <= idx < len(metadata):
            results.append(metadata[idx])
    return results


# ------------------------------------------------
# RAG ë¦¬í¬íŠ¸ ìƒì„±
# ------------------------------------------------
def generate_rag_summary(mct_id: str, mode: str = "v1", top_k: int = 5) -> Dict[str, Any]:
    """
    ê° ëª¨ë¸(v1/v2/v3)ì˜ reports ë²¡í„°DB + ê³µí†µ segments ë²¡í„°DBë¥¼ í•¨ê»˜ ê²€ìƒ‰í•˜ì—¬
    Gemini-2.5-Flashê°€ í†µí•© ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    print(f"ğŸš€ [RAG Triggered] mct_id={mct_id}, mode={mode}")
    try:
        # âœ… analyzer/ ê¸°ì¤€ìœ¼ë¡œ vector_dbs ê²½ë¡œ ì§€ì •
        base_dir = os.path.dirname(os.path.abspath(__file__))  
        report_folder = os.path.join(base_dir, "vector_dbs", mode)
        shared_folder = os.path.join(base_dir, "vector_dbs", "shared")


        print(f"ğŸ“‚ ë³´ê³ ì„œ ë²¡í„° ê²½ë¡œ: {report_folder}")
        print(f"ğŸ“‚ ì„¸ê·¸ë¨¼íŠ¸ ë²¡í„° ê²½ë¡œ: {shared_folder}")


        # âœ… ê° í´ë”ì—ì„œ ë²¡í„°DB ë¡œë“œ
        reports_index, reports_meta = load_vector_db(report_folder, "marketing_reports")
        segments_index, segments_meta = load_vector_db(shared_folder, "marketing_segments")

        print(f"âœ… reports_meta ê°œìˆ˜: {len(reports_meta)}")
        print(f"âœ… segments_meta ê°œìˆ˜: {len(segments_meta)}")

        os.environ["TOKENIZERS_PARALLELISM"] = "false"  # M1 ë³‘ë ¬ ê²½ê³  ë°©ì§€

        # âœ… ì„ë² ë”© ëª¨ë¸ (BGE-M3)
        from sentence_transformers import SentenceTransformer
        embedder = SentenceTransformer("BAAI/bge-m3")

        # âœ… ì¿¼ë¦¬ ë²¡í„° ë³€í™˜ ë¶€ë¶„ë„ ê°™ì´ ìˆ˜ì •í•´ì•¼ í•¨
        query_emb = embedder.encode([mct_id], normalize_embeddings=True)
        query_vector = np.array(query_emb, dtype=np.float32)

        # âœ… ê° ë²¡í„°DBì—ì„œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
        report_results = retrieve_similar_docs(reports_index, reports_meta, query_vector, top_k)
        segment_results = retrieve_similar_docs(segments_index, segments_meta, query_vector, top_k)

        if not report_results and not segment_results:
            return {"error": f"'{mct_id}' ê´€ë ¨ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        # ------------------------------------------------
        # context ì¡°í•©
        # ------------------------------------------------
        report_context = "\n\n".join([r["text"] for r in report_results])
        segment_context = "\n\n".join([r["text"] for r in segment_results])

        combined_context = f"""
        [ë§¤ì¥ ë¶„ì„ ë°ì´í„°]
        {report_context}

        [ë§ˆì¼€íŒ… ì „ëµ ë°ì´í„°]
        {segment_context}
        """

        # ------------------------------------------------
        # Gemini í”„ë¡¬í”„íŠ¸
        # ------------------------------------------------
        prompt = f"""
        ë‹¤ìŒì€ '{mct_id}' ë§¤ì¥ê³¼ ìœ ì‚¬í•œ ì‚¬ë¡€ë“¤ì˜ ë°ì´í„°ì…ë‹ˆë‹¤.
        ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AI ë§ˆì¼€íŒ… ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

        {combined_context}

        ì‘ì„± ì§€ì¹¨:
        1ï¸âƒ£ ë§¤ì¥ í•µì‹¬ ìš”ì•½ (í˜„ì¬ ìƒíƒœë¥¼ í•œ ë¬¸ë‹¨ìœ¼ë¡œ)
        2ï¸âƒ£ ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ (3ê°œ ì´ìƒ)
        3ï¸âƒ£ ì£¼ìš” ë¬¸ì œì  ë° ì›ì¸
        4ï¸âƒ£ ê°œì„  ì „ëµ (ë‹¨ê¸°/ì¤‘ê¸°/ì¥ê¸°ë³„ êµ¬ì²´ì  ì‹¤í–‰ì•ˆ í¬í•¨)
        5ï¸âƒ£ ê²°ë¡  ë° ìš°ì„ ìˆœìœ„ ìš”ì•½

        âš™ï¸ ë‹¨ìˆœ ìš”ì•½ì´ ì•„ë‹ˆë¼, ë°ì´í„°ì— ê¸°ë°˜í•œ ë¶„ì„ì  ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
        """

        model = genai.GenerativeModel("gemini-2.5-flash")
        response = model.generate_content(prompt)

        print(prompt)

        return {
            "store_code": mct_id,
            "rag_summary": response.text,
            "references": {
                "reports": [r.get("store_name", "N/A") for r in report_results],
                "segments": [r.get("title", r.get("category", "ê³µí†µ ì „ëµ")) for r in segment_results],
            },
        }

    except Exception as e:
        print(str(e))
        return {"error": str(e), "traceback": traceback.format_exc(limit=2)}
