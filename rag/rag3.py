"""
RAG3: ìš”ì‹ì—… ê°€ë§¹ì  ë¬¸ì œ ì§„ë‹¨ ë° í•´ê²° ì»¨ì„¤íŒ… ì‹œìŠ¤í…œ (ì›¹í˜ì´ì§€ìš©)
- LLMì´ ëª¨ë¸ë§ ê²°ê³¼ì™€ RAG ë¬¸ì„œë¥¼ ë¶„ì„í•˜ì—¬ ë§ì¶¤í˜• ì†”ë£¨ì…˜ ìƒì„±
- ì›¹í˜ì´ì§€ì— í‘œì‹œí•  ê°„ê²°í•œ ë‹µë³€ í˜•ì‹
- 3ê°œ ì„¹ì…˜: ì¸ì‚¬ì´íŠ¸ 2ê°œ + ì „ëµ 2ê°œ + ì†”ë£¨ì…˜ 2ê°œ
"""

import os
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from pathlib import Path
import warnings
import google.generativeai as genai

warnings.filterwarnings('ignore')


class RAG3ConsultingSystem:
    """LLM ê¸°ë°˜ ìš”ì‹ì—… ì»¨ì„¤íŒ… ì‹œìŠ¤í…œ (ì›¹í˜ì´ì§€ìš©)"""
    
    def __init__(self, data_folder_path, gemini_api_key):
        self.data_folder = Path(data_folder_path)
        
        print("ğŸ”„ ìš”ì‹ì—… ì»¨ì„¤íŒ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        self.model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
        
        genai.configure(api_key=gemini_api_key)
        self.gemini_model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        self.documents = []
        self.doc_embeddings = None
    
    def load_documents(self):
        """RAG ë¬¸ì„œ ë¡œë”©"""
        print("\nğŸ“š RAG ë¬¸ì„œ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì¤‘...")
        
        excel_files = list(self.data_folder.glob('*.xlsx'))
        
        for file_path in excel_files:
            try:
                df = pd.read_excel(file_path, sheet_name=0)
                file_name = file_path.stem
                content = self._extract_content_from_df(df, file_name)
                
                self.documents.append({
                    'file_name': file_name,
                    'content': content,
                    'raw_data': df.to_string()[:3000]
                })
                
                print(f"  âœ“ {file_name}")
                
            except Exception as e:
                print(f"  âœ— {file_path.name}: {str(e)}")
        
        print(f"\nâœ… ì´ {len(self.documents)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ!\n")
        
    def _extract_content_from_df(self, df, file_name):
        """ë°ì´í„°í”„ë ˆì„ â†’ í…ìŠ¤íŠ¸ ë³€í™˜"""
        content_parts = [file_name]
        content_parts.append(" ".join([str(col) for col in df.columns if pd.notna(col)]))
        
        for idx, row in df.head(30).iterrows():
            row_text = " ".join([str(val) for val in row if pd.notna(val) and str(val).strip()])
            if row_text:
                content_parts.append(row_text)
        
        return " ".join(content_parts)
    
    def build_embeddings(self):
        """ë¬¸ì„œ ì„ë² ë”© ìƒì„±"""
        if len(self.documents) == 0:
            print("âŒ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤!")
            return False
        
        print("ğŸ”„ ë¬¸ì„œ ì„ë² ë”© ìƒì„± ì¤‘...")
        contents = [doc['content'] for doc in self.documents]
        self.doc_embeddings = self.model.encode(contents, show_progress_bar=True)
        print("âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ!\n")
        return True
    
    def search_documents(self, problem_name, industry, store_name, market_context, top_k=3):
        """
        LLM ê¸°ë°˜ ìœ ì—°í•œ RAG ë¬¸ì„œ ê²€ìƒ‰
        - ë¬¸ì œëª… + ì—…ì¢… + ë§¤ì¥ëª… + ìƒê¶Œ íŠ¹ì„±ìœ¼ë¡œ ê²€ìƒ‰ ì¿¼ë¦¬ ìë™ ìƒì„±
        """
        
        if len(self.documents) == 0 or self.doc_embeddings is None:
            return []
        
        # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± (ëª¨ë“  ì»¨í…ìŠ¤íŠ¸ í™œìš©)
        search_query = f"{problem_name} {industry} {store_name} {market_context} ì™¸ì‹ ì†Œë¹„ì í–‰íƒœ ë§ˆì¼€íŒ…"
        
        print(f"ğŸ” RAG ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
        print(f"  ë¬¸ì œ: {problem_name}")
        print(f"  ì—…ì¢…: {industry}")
        print(f"  ìƒê¶Œ: {market_context}")
        print(f"  ê²€ìƒ‰ ì¿¼ë¦¬: {search_query}\n")
        
        # ì„ë² ë”© ê²€ìƒ‰
        query_embedding = self.model.encode([search_query])
        similarities = cosine_similarity(query_embedding, self.doc_embeddings)[0]
        top_indices = np.argsort(similarities)[-top_k:][::-1]
        
        results = []
        print(f"ğŸ“Š ê´€ë ¨ë„ ë†’ì€ ìƒìœ„ {top_k}ê°œ ë¬¸ì„œ:\n")
        
        for rank, idx in enumerate(top_indices, 1):
            doc = self.documents[idx]
            similarity_score = similarities[idx] * 100
            
            results.append({
                'rank': rank,
                'file_name': doc['file_name'],
                'similarity': similarity_score,
                'raw_data': doc['raw_data']
            })
            
            print(f"  {rank}. [{similarity_score:.1f}%] {doc['file_name']}")
        
        print()
        return results
    
    def generate_consulting_response(self, modeling_data, relevant_docs):
        """
        ì›¹í˜ì´ì§€ìš© ì»¨ì„¤íŒ… ë‹µë³€ ìƒì„±
        - ê°„ê²°í•˜ê³  ì½ê¸° ì‰¬ìš´ í˜•ì‹
        - LLMì´ ëª¨ë¸ë§ ê²°ê³¼ì™€ RAG ë¬¸ì„œë¥¼ ë¶„ì„í•˜ì—¬ ë§ì¶¤í˜• ë‹µë³€ ìƒì„±
        """
        
        print("=" * 80)
        print("ğŸ¯ ì›¹í˜ì´ì§€ìš© ì»¨ì„¤íŒ… ë‹µë³€ ìƒì„± ì¤‘...")
        print("=" * 80)
        print()
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self._build_prompt(modeling_data, relevant_docs)
        
        try:
            response = self.gemini_model.generate_content(prompt)
            
            print("âœ… ì»¨ì„¤íŒ… ë‹µë³€ ìƒì„± ì™„ë£Œ!\n")
            print("=" * 80)
            print("ğŸ“‹ ì»¨ì„¤íŒ… ë‹µë³€")
            print("=" * 80)
            print()
            print(response.text)
            print()
            print("=" * 80)
            
            return response.text
            
        except Exception as e:
            print(f"âŒ Gemini API ì˜¤ë¥˜: {str(e)}")
            return None
    
    def _build_prompt(self, modeling_data, relevant_docs):
        """
        ì›¹í˜ì´ì§€ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±
        - ê°„ê²°í•œ ë‹µë³€ í˜•ì‹
        """
        
        # ìµœìš°ì„  ë¬¸ì œ
        top_issue = modeling_data['analysis']['diagnosis_top3'][0]
        problem_name = top_issue['ì•½ì ']
        severity = top_issue['ì‹¬ê°ë„']
        
        # ê¸°íƒ€ ë¬¸ì œë“¤
        other_issues = ""
        for idx, issue in enumerate(modeling_data['analysis']['diagnosis_top3'][1:], 2):
            other_issues += f"{idx}ìˆœìœ„: {issue['ì•½ì ']} (ì‹¬ê°ë„ {issue['ì‹¬ê°ë„']})\n"
        
        # RAG ë¬¸ì„œ ì •ë³´ (ì†ë„ ê°œì„ : 1000ìë¡œ ì¶•ì†Œ)
        docs_info = ""
        for doc in relevant_docs:
            docs_info += f"\n**[ë¬¸ì„œ {doc['rank']}] {doc['file_name']}** (ê´€ë ¨ë„ {doc['similarity']:.0f}%)\n"
            docs_info += f"```\n{doc['raw_data'][:1000]}\n```\n"
        
        # ì¶”ì²œì‚¬í•­
        recommendations = "\n".join([f"- {rec}" for rec in modeling_data.get('recommendations', [])])
        
        industry = modeling_data.get('industry', 'ìš”ì‹ì—…')
        market_context = modeling_data['analysis']['market_type_context']
        
        prompt = f"""ë‹¹ì‹ ì€ ìš”ì‹ì—… ì „ë¬¸ ê²½ì˜ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ë§¤ì¥ì˜ ë¬¸ì œë¥¼ ì§„ë‹¨í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ í•´ê²°ì±…ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ“ ë§¤ì¥ ì •ë³´
- **ë§¤ì¥ëª…**: {modeling_data['store_name']}
- **ì—…ì¢…**: {industry}
- **ìƒê¶Œ íŠ¹ì„±**: {market_context}

## ğŸš¨ ëª¨ë¸ë§ ì§„ë‹¨ ê²°ê³¼

### ìµœìš°ì„  í•´ê²° ê³¼ì œ
**ë¬¸ì œ**: {problem_name}
**ì‹¬ê°ë„**: {severity}/100

### ê¸°íƒ€ ë°œê²¬ëœ ë¬¸ì œ
{other_issues}

### ëª¨ë¸ë§ ì¶”ì²œì‚¬í•­
{recommendations}

## ğŸ“š RAG ì°¸ê³  ë¬¸ì„œ (ì™¸ì‹ì—… ë¹…ë°ì´í„°)
{docs_info}

---

## ğŸ“ ë‹µë³€ ì‘ì„± ì§€ì‹œì‚¬í•­

ì›¹í˜ì´ì§€ì— í‘œì‹œí•  ê°„ê²°í•œ ì»¨ì„¤íŒ… ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.

### ğŸ“Š ì„¹ì…˜ 1: ì‹œì¥ ì¸ì‚¬ì´íŠ¸ (2ê°œ)

RAG ë¬¸ì„œì—ì„œ ë°œê²¬í•œ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 2ê°€ì§€ë¥¼ ë¶„ì„í•˜ì„¸ìš”.

**ì‘ì„± í˜•ì‹**:
- ğŸ’¡ **ì¸ì‚¬ì´íŠ¸ 1**: [í•µì‹¬ íŠ¸ë Œë“œ]
  * ë°ì´í„°: [ë¬¸ì„œëª…]ì—ì„œ "..." (ê°„ë‹¨íˆ)
  * ì ìš© ë°©ë²•: 1-2ë¬¸ì¥ìœ¼ë¡œ ìš°ë¦¬ ë§¤ì¥ì— ì–´ë–»ê²Œ ì ìš©í• ì§€

- ğŸ’¡ **ì¸ì‚¬ì´íŠ¸ 2**: [ì†Œë¹„ì í–‰íƒœ]
  * ë°ì´í„°: [ë¬¸ì„œëª…]ì—ì„œ "..."
  * ì ìš© ë°©ë²•: 1-2ë¬¸ì¥

---

### ğŸ¯ ì„¹ì…˜ 2: ë§¤ì¥ ë§ì¶¤ ì „ëµ (2ê°œ)

ìƒê¶Œ íŠ¹ì„±({market_context})ê³¼ ì—…ì¢…({industry})ì„ ë°˜ì˜í•œ ì°¨ë³„í™” ì „ëµì„ ì œì‹œí•˜ì„¸ìš”.

**ì‘ì„± í˜•ì‹**:
- ğŸ¯ **ì „ëµ 1**: [ì „ëµëª…]
  * ì´ìœ : 1ë¬¸ì¥ìœ¼ë¡œ ì™œ í•„ìš”í•œì§€
  * ë°©ë²•: 2-3ë¬¸ì¥ìœ¼ë¡œ êµ¬ì²´ì  ì‹¤í–‰ ë°©ë²•
  * íš¨ê³¼: ~í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤ (1ë¬¸ì¥)

- ğŸ¯ **ì „ëµ 2**: [ì „ëµëª…]
  * ì´ìœ : 1ë¬¸ì¥
  * ë°©ë²•: 2-3ë¬¸ì¥
  * íš¨ê³¼: ~ì— ë„ì›€ì´ ë  ê²ƒì…ë‹ˆë‹¤ (1ë¬¸ì¥)

---

### ğŸ”§ ì„¹ì…˜ 3: ìµœìš°ì„  ë¬¸ì œ í•´ê²° ì „ëµ â­

**ë¬¸ì œ**: {problem_name} (ì‹¬ê°ë„ {severity}/100)

#### ì›ì¸ ë¶„ì„
ëª¨ë¸ë§ ê²°ê³¼ì™€ ìƒê¶Œ íŠ¹ì„±ì„ ë°”íƒ•ìœ¼ë¡œ ì´ ë¬¸ì œê°€ ë°œìƒí•œ ì›ì¸ì„ 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë¶„ì„í•˜ì„¸ìš”.

#### ì‹¤í–‰ ì†”ë£¨ì…˜ (2ê°œ)

ğŸ’¡ **ì†”ë£¨ì…˜ 1**: [ì œëª©]
  * ì‹¤í–‰ ë°©ë²•: 
    - 3-4ë¬¸ì¥ìœ¼ë¡œ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…
  * ì˜ˆì‚°: ì•½ Xë§Œì›
  * ê¸°ê°„: Xì£¼
  * RAG ê·¼ê±°: [ë¬¸ì„œëª…]ì˜ ë°ì´í„°ë¥¼ ì¸ìš©í•˜ì—¬ ê·¼ê±° ì œì‹œ
  * ì˜ˆìƒ íš¨ê³¼: ~í•˜ëŠ” ë° ë„ì›€ì´ ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤ (1-2ë¬¸ì¥)

ğŸ’¡ **ì†”ë£¨ì…˜ 2**: [ì œëª©]
  * ì‹¤í–‰ ë°©ë²•:
    - 3-4ë¬¸ì¥ìœ¼ë¡œ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…
  * ì˜ˆì‚°: ì•½ Xë§Œì›
  * ê¸°ê°„: Xì£¼
  * RAG ê·¼ê±°: [ë¬¸ì„œëª…]ì˜ ë°ì´í„°ë¥¼ ì¸ìš©
  * ì˜ˆìƒ íš¨ê³¼: ~í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤ (1-2ë¬¸ì¥)

---

## âš ï¸ ì‘ì„± ì›ì¹™
1. **ì›¹í˜ì´ì§€ìš© ê°„ê²°í•œ ë‹µë³€**: ê³¼ë„í•˜ê²Œ ê¸¸ì§€ ì•Šê²Œ
2. **ì „ë¬¸ì ì´ì§€ë§Œ ì½ê¸° ì‰½ê²Œ**: ì¹œê·¼í•œ í†¤
3. **RAG ë°ì´í„° ê·¼ê±° ì œì‹œ**: ë°˜ë“œì‹œ ë¬¸ì„œëª…ê³¼ ë°ì´í„° ì¸ìš©
4. **ì‹¤í–‰ ê°€ëŠ¥ì„±**: êµ¬ì²´ì ì´ê³  í˜„ì‹¤ì ì¸ ë°©ë²• ì œì‹œ
5. **{industry} íŠ¹ì„± ë°˜ì˜**: ì—…ì¢…ì— ë§ëŠ” ë§ì¶¤í˜• ì†”ë£¨ì…˜

ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ë‹µê²Œ ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ì¸ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”!
"""
        
        return prompt


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # Gemini API í‚¤
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "ì—¬ê¸°ì—_API_í‚¤_ì…ë ¥")
    
    if GEMINI_API_KEY == "ì—¬ê¸°ì—_API_í‚¤_ì…ë ¥":
        print("âš ï¸  Gemini API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”!")
        print("export GEMINI_API_KEY='your-api-key'")
        return
    
    # 1. RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    data_folder = r"C:\Temp\data\ragë°ì´í„°_ë³‘ì§„ë‹˜"
    
    try:
        rag = RAG3ConsultingSystem(data_folder, GEMINI_API_KEY)
    except Exception as e:
        print(f"âŒ ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")
        return
    
    # 2. ë¬¸ì„œ ë¡œë“œ ë° ì„ë² ë”© ìƒì„±
    try:
        rag.load_documents()
    except Exception as e:
        print(f"âŒ ë¬¸ì„œ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        print("í•´ê²° ë°©ë²•: pip install openpyxl")
        return
    
    if len(rag.documents) == 0:
        print("\nâš ï¸  ë¬¸ì„œë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    if not rag.build_embeddings():
        return
    
    # 3. ìƒ˜í”Œ ë°ì´í„°: ì„±ë™êµ¬ ì¼ì‹ë‹¹
    modeling_data = {
        "store_code": "00803E9174",
        "store_name": "ìš°ë™ëª…ê°€ ì™•ì‹­ë¦¬ì ",
        "industry": "ì¼ì‹ë‹¹",
        "status": "ì§„ë‹¨ ì™„ë£Œ",
        "analysis": {
            "type": "ì‹œê³„ì—´ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ì§„ë‹¨",
            "market_type_context": "ìš°ë™ë°€ì§‘í˜• ìƒê¶Œ (ê²½ìŸ ë§¤ì¥ 12ê°œ)",
            "diagnosis_top3": [
                {
                    "ì•½ì ": "ìƒê¶Œ ë‚´ ê²½ìŸ ì‹¬í™”",
                    "ì‹¬ê°ë„": 92
                },
                {
                    "ì•½ì ": "ê°ë‹¨ê°€ í•˜ë½",
                    "ì‹¬ê°ë„": 82
                },
                {
                    "ì•½ì ": "ë§¤ì¶œ ê·œëª¨ ê°ì†Œ",
                    "ì‹¬ê°ë„": 62
                }
            ]
        },
        "recommendations": [
            "ê²½ìŸì ê³¼ ì°¨ë³„í™”ë˜ëŠ” ìš°ë¦¬ ê°€ê²Œë§Œì˜ ì‹œê·¸ë‹ˆì²˜ ë©”ë‰´ ê°œë°œ",
            "ê°€ì¹˜ ìƒìŠ¹ì„ ìœ„í•œ ì„¸íŠ¸ ë©”ë‰´ ê°œë°œ ë˜ëŠ” ë©”ë‰´ ê³ ê¸‰í™”",
            "ë§¤ì¶œ ì¦ëŒ€ë¥¼ ìœ„í•œ í”¼í¬íƒ€ì„ ì„¸íŠ¸ ë©”ë‰´ ì¶œì‹œ ë˜ëŠ” ë°°ë‹¬ í™œì„±í™”"
        ]
    }
    
    print("\n" + "=" * 80)
    print("ğŸª ë§¤ì¥ ì •ë³´")
    print("=" * 80)
    print(f"ë§¤ì¥ëª…: {modeling_data['store_name']}")
    print(f"ì—…ì¢…: {modeling_data['industry']}")
    print(f"ìƒê¶Œ íŠ¹ì„±: {modeling_data['analysis']['market_type_context']}")
    print(f"\nìµœìš°ì„  ë¬¸ì œ: {modeling_data['analysis']['diagnosis_top3'][0]['ì•½ì ']}")
    print(f"ì‹¬ê°ë„: {modeling_data['analysis']['diagnosis_top3'][0]['ì‹¬ê°ë„']}/100")
    print("=" * 80)
    
    # 4. RAG ë¬¸ì„œ ê²€ìƒ‰ (ë™ì )
    top_issue = modeling_data['analysis']['diagnosis_top3'][0]
    
    relevant_docs = rag.search_documents(
        problem_name=top_issue['ì•½ì '],
        industry=modeling_data['industry'],
        store_name=modeling_data['store_name'],
        market_context=modeling_data['analysis']['market_type_context'],
        top_k=3
    )
    
    if len(relevant_docs) == 0:
        print("âŒ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # 5. ì›¹í˜ì´ì§€ìš© ì»¨ì„¤íŒ… ë‹µë³€ ìƒì„±
    response = rag.generate_consulting_response(modeling_data, relevant_docs)
    
    # 6. ê²°ê³¼ ì €ì¥
    if response:
        try:
            output_file = "consulting_response.txt"
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write("=" * 80 + "\n")
                f.write("ğŸ“‹ ì»¨ì„¤íŒ… ë‹µë³€\n")
                f.write("=" * 80 + "\n\n")
                f.write(f"ë§¤ì¥ëª…: {modeling_data['store_name']}\n")
                f.write(f"ì—…ì¢…: {modeling_data['industry']}\n")
                f.write(f"ìƒì„±ì¼: {pd.Timestamp.now()}\n\n")
                f.write(f"ìµœìš°ì„  í•´ê²° ê³¼ì œ: {top_issue['ì•½ì ']} (ì‹¬ê°ë„ {top_issue['ì‹¬ê°ë„']}/100)\n\n")
                f.write("ì°¸ê³  ë¬¸ì„œ:\n")
                for doc in relevant_docs:
                    f.write(f"  - [{doc['similarity']:.1f}%] {doc['file_name']}\n")
                f.write("\n" + "=" * 80 + "\n\n")
                f.write(response)
            
            print(f"\nğŸ“„ ì»¨ì„¤íŒ… ë‹µë³€ì´ '{output_file}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âš ï¸  íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {str(e)}")


if __name__ == "__main__":
    main()