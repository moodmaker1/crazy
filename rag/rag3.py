"""
RAG3: ìš”ì‹ì—… ê°€ë§¹ì  ë¬¸ì œ ì§„ë‹¨ ë° í•´ê²° ì»¨ì„¤íŒ… ì‹œìŠ¤í…œ

ì‚¬ìš©ë²•:
1. ì•„ë˜ GEMINI_API_KEYì™€ data_folder ê²½ë¡œ ì„¤ì •
2. python rag3.py ì‹¤í–‰
3. consulting_response.txt íŒŒì¼ í™•ì¸
"""

import os
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from pathlib import Path
import warnings
import google.generativeai as genai

warnings.filterwarnings('ignore')


class RAG3ConsultingSystem:
    """LLM ê¸°ë°˜ ìš”ì‹ì—… ì»¨ì„¤íŒ… ì‹œìŠ¤í…œ"""
    
    # 12ê°œ ë¬¸ì œ ìœ í˜• ì •ì˜
    PROBLEM_TYPES = {
        "ì¬ë°©ë¬¸ìœ¨ ì €ì¡°": "ì¶©ì„± ê³ ê° í™•ë³´ë¥¼ ìœ„í•œ ì¿ í°/ìŠ¤íƒ¬í”„ ì œë„ ë„ì…",
        "ì‹ ê·œê³ ê° ìœ ì… ë¶€ì¡±": "ì‹ ê·œ ê³ ê° íƒ€ê²Ÿ ë°°ë‹¬ì•± í• ì¸ ë˜ëŠ” ì²« ë°©ë¬¸ ì´ë²¤íŠ¸",
        "ê°ë‹¨ê°€ í•˜ë½": "ê°€ì¹˜ ìƒìŠ¹ì„ ìœ„í•œ ì„¸íŠ¸ ë©”ë‰´ ê°œë°œ ë˜ëŠ” ë©”ë‰´ ê³ ê¸‰í™”",
        "ì¶©ì„±ë„ í•˜ë½": "ë‹¨ê³¨ ê³ ê° ëŒ€ìƒ íŠ¹ë³„ í˜œíƒ ë˜ëŠ” ì¬ë°©ë¬¸ ê°ì‚¬ í”„ë¡œëª¨ì…˜",
        "ë§¤ì¶œ ë³€ë™ì„± ì‹¬í™”": "ì•ˆì •ì  ë§¤ì¶œ í™•ë³´ë¥¼ ìœ„í•œ ì ì‹¬ êµ¬ë… ì„œë¹„ìŠ¤ ë˜ëŠ” ì •ê¸° ì´ë²¤íŠ¸ ê¸°íš",
        "ê³ ê° ì´íƒˆ ì‹¬í™”": "ê³ ê° í”¼ë“œë°± ì±„ë„ ë§ˆë ¨ ë° ì„œë¹„ìŠ¤ ë§Œì¡±ë„ ê°œì„  ìº í˜ì¸",
        "ìƒê¶Œ ë‚´ ê²½ìŸ ì‹¬í™”": "ê²½ìŸì ê³¼ ì°¨ë³„í™”ë˜ëŠ” ìš°ë¦¬ ê°€ê²Œë§Œì˜ ì‹œê·¸ë‹ˆì²˜ ë©”ë‰´ ê°œë°œ",
        "ìœ ë™ê³ ê° ì˜ì¡´ë„ ì‹¬í™”": "ì£¼ë³€ ê±°ì£¼/ì§ì¥ì¸ ëŒ€ìƒ ë¡œì»¬ ë§ˆì¼€íŒ… ê°•í™”",
        "ë°°ë‹¬ íš¨ìœ¨ ì €í•˜": "ë°°ë‹¬ ì£¼ë¬¸ ì „ìš© ë©”ë‰´ ê°œë°œ ë˜ëŠ” ìµœì†Œì£¼ë¬¸ê¸ˆì•¡ ì¡°ì •",
        "íŠ¹ì •ê³ ê° ì ë¦¼ ì‹¬í™”": "ìƒˆë¡œìš´ ê³ ê°ì¸µ ìœ ì…ì„ ìœ„í•œ íƒ€ê²Ÿ í”„ë¡œëª¨ì…˜ (ì˜ˆ: 1020ì„¸ëŒ€ ì´ë²¤íŠ¸)",
        "ë§¤ì¶œ ê·œëª¨ ê°ì†Œ": "ë§¤ì¶œ ì¦ëŒ€ë¥¼ ìœ„í•œ í”¼í¬íƒ€ì„ ì„¸íŠ¸ ë©”ë‰´ ì¶œì‹œ ë˜ëŠ” ë°°ë‹¬ í™œì„±í™”",
        "ê³ ê° ë°©ë¬¸ ë¹ˆë„ ê°ì†Œ": "ì¬ë°©ë¬¸ ìœ ë„ë¥¼ ìœ„í•œ ë§ˆì¼ë¦¬ì§€ ì œë„ ë˜ëŠ” ìš”ì¼ë³„ ì´ë²¤íŠ¸"
    }
    
    def __init__(self, data_folder_path, gemini_api_key):
        self.data_folder = Path(data_folder_path)
        
        print("ğŸ”„ ìš”ì‹ì—… ì»¨ì„¤íŒ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        self.model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
        
        genai.configure(api_key=gemini_api_key)
        self.gemini_model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        self.documents = []
        self.doc_embeddings = None
    
    def load_documents(self):
        """RAG ë¬¸ì„œ ë¡œë”©"""
        print("\nğŸ“š RAG ë¬¸ì„œ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì¤‘...")
        
        excel_files = list(self.data_folder.glob('*.xlsx'))
        
        for file_path in excel_files:
            try:
                df = pd.read_excel(file_path, sheet_name=0)
                file_name = file_path.stem
                
                # í…ìŠ¤íŠ¸ ë³€í™˜
                content_parts = [file_name]
                content_parts.append(" ".join([str(col) for col in df.columns if pd.notna(col)]))
                
                for idx, row in df.head(30).iterrows():
                    row_text = " ".join([str(val) for val in row if pd.notna(val) and str(val).strip()])
                    if row_text:
                        content_parts.append(row_text)
                
                content = " ".join(content_parts)
                
                self.documents.append({
                    'file_name': file_name,
                    'content': content,
                    'raw_data': df.to_string()[:1500]
                })
                
                print(f"  âœ“ {file_name}")
                
            except Exception as e:
                print(f"  âœ— {file_path.name}: {str(e)}")
        
        print(f"\nâœ… ì´ {len(self.documents)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ!\n")
    
    def build_embeddings(self):
        """ë¬¸ì„œ ì„ë² ë”© ìƒì„±"""
        if len(self.documents) == 0:
            print("âŒ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤!")
            return False
        
        print("ğŸ”„ ë¬¸ì„œ ì„ë² ë”© ìƒì„± ì¤‘...")
        contents = [doc['content'] for doc in self.documents]
        self.doc_embeddings = self.model.encode(contents, show_progress_bar=True)
        print("âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ!\n")
        return True
    
    def search_documents(self, problem_name, industry, store_name, market_context, top_k=2):
        """RAG ë¬¸ì„œ ê²€ìƒ‰"""
        
        if len(self.documents) == 0 or self.doc_embeddings is None:
            return []
        
        search_query = f"{problem_name} {industry} {store_name} {market_context} ì™¸ì‹ ì†Œë¹„ì í–‰íƒœ ë§ˆì¼€íŒ…"
        
        print(f"ğŸ” RAG ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
        print(f"  ë¬¸ì œ: {problem_name}")
        print(f"  ì—…ì¢…: {industry}")
        print(f"  ìƒê¶Œ: {market_context}")
        
        query_embedding = self.model.encode([search_query])
        similarities = cosine_similarity(query_embedding, self.doc_embeddings)[0]
        top_indices = np.argsort(similarities)[-top_k:][::-1]
        
        results = []
        print(f"\nğŸ“Š ê´€ë ¨ë„ ë†’ì€ ìƒìœ„ {top_k}ê°œ ë¬¸ì„œ:\n")
        
        for rank, idx in enumerate(top_indices, 1):
            doc = self.documents[idx]
            similarity_score = similarities[idx] * 100
            
            results.append({
                'rank': rank,
                'file_name': doc['file_name'],
                'similarity': similarity_score,
                'raw_data': doc['raw_data']
            })
            
            print(f"  {rank}. [{similarity_score:.1f}%] {doc['file_name']}")
        
        print()
        return results
    
    def generate_consulting_response(self, modeling_data, relevant_docs):
        """ì»¨ì„¤íŒ… ë‹µë³€ ìƒì„±"""
        
        print("=" * 80)
        print("ğŸ¯ ì»¨ì„¤íŒ… ë‹µë³€ ìƒì„± ì¤‘...")
        print("=" * 80)
        print()
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        top_issue = modeling_data['analysis']['diagnosis_top3'][0]
        problem_name = top_issue['ì•½ì ']
        severity = top_issue['ì‹¬ê°ë„']
        
        # ê¸°ë³¸ ì†”ë£¨ì…˜ ê°€ì ¸ì˜¤ê¸°
        base_solution = self.PROBLEM_TYPES.get(problem_name, "ë§ì¶¤ ì „ëµ ê°œë°œ í•„ìš”")
        
        # ëª¨ë“  ë¬¸ì œ ì •ë¦¬
        all_issues = ""
        for idx, issue in enumerate(modeling_data['analysis']['diagnosis_top3'], 1):
            base_sol = self.PROBLEM_TYPES.get(issue['ì•½ì '], "ë§ì¶¤ ì „ëµ í•„ìš”")
            all_issues += f"{idx}. **{issue['ì•½ì ']}** (ì‹¬ê°ë„ {issue['ì‹¬ê°ë„']}/100)\n"
            all_issues += f"   â†’ ê¸°ë³¸ ì†”ë£¨ì…˜: {base_sol}\n\n"
        
        docs_info = ""
        for doc in relevant_docs:
            docs_info += f"**[{doc['rank']}] {doc['file_name']}** (ìœ ì‚¬ë„ {doc['similarity']:.0f}%)\n"
            docs_info += f"```\n{doc['raw_data']}\n```\n\n"
        
        industry = modeling_data.get('industry', 'ìš”ì‹ì—…')
        market_context = modeling_data['analysis']['market_type_context']
        
        prompt = f"""ë‹¹ì‹ ì€ ìš”ì‹ì—… ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
        
ë§¤ì¥ì˜ **ê°€ì¥ í° ë¬¸ì œì **ê³¼ ì´ë¥¼ í•´ê²°í•  **êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë§ˆì¼€íŒ… ì•„ì´ë””ì–´**ë¥¼ RAG ë°ì´í„° ê·¼ê±°ì™€ í•¨ê»˜ ì œì‹œí•˜ì„¸ìš”.

## ğŸ“ ë§¤ì¥ ì •ë³´
- **ë§¤ì¥ëª…**: {modeling_data['store_name']}
- **ì—…ì¢…**: {industry}
- **ìƒê¶Œ íŠ¹ì„±**: {market_context}

## ğŸš¨ ì§„ë‹¨ ê²°ê³¼ (ëª¨ë¸ë§ ë¶„ì„)
{all_issues}

## ğŸ“š RAG ì°¸ê³  ë¬¸ì„œ (ì™¸ì‹ì—… ë°ì´í„°)
{docs_info}

---

## âœ… ë‹µë³€ í˜•ì‹ (ë°˜ë“œì‹œ ì¤€ìˆ˜)

# {modeling_data['store_name']} ë§ˆì¼€íŒ… ì»¨ì„¤íŒ… ë¦¬í¬íŠ¸

## ğŸ¯ 1. í•µì‹¬ ë¬¸ì œ ì§„ë‹¨

### ìµœìš°ì„  í•´ê²° ê³¼ì œ: **{problem_name}** (ì‹¬ê°ë„ {severity}/100)

**[ë¬¸ì œ ìƒí™©]**
- í˜„ì¬ ìƒí™©: (ìƒê¶Œ íŠ¹ì„±ê³¼ ì—°ê³„í•˜ì—¬ 1-2ë¬¸ì¥)
- ë°œìƒ ì›ì¸: (RAG ë°ì´í„° ê·¼ê±° 1-2ë¬¸ì¥)

**[RAG ë°ì´í„° ê·¼ê±°]**
- **[ë¬¸ì„œ1]**: (í•µì‹¬ ë°ì´í„° ì¸ìš©, ìˆ˜ì¹˜ í¬í•¨)
- **[ë¬¸ì„œ2]**: (ì¶”ê°€ ê·¼ê±° ë°ì´í„°, íŠ¸ë Œë“œ)

---

## ğŸ’¡ 2. ë§ì¶¤ ë§ˆì¼€íŒ… ì „ëµ (ì‹¤í–‰ ì¤‘ì‹¬)

### ì „ëµ 1: [êµ¬ì²´ì  ì „ëµëª…]
- **ëª©í‘œ**: {problem_name} í•´ê²°ì„ ìœ„í•œ í•µì‹¬ ëª©í‘œ
- **ì‹¤í–‰ ë°©ë²•**: 
  1. (êµ¬ì²´ì  ì‹¤í–‰ ë‹¨ê³„ 1 - ëˆ„ê°€, ì–¸ì œ, ë¬´ì—‡ì„)
  2. (êµ¬ì²´ì  ì‹¤í–‰ ë‹¨ê³„ 2)
  3. (êµ¬ì²´ì  ì‹¤í–‰ ë‹¨ê³„ 3)
- **ì˜ˆìƒ íš¨ê³¼**: (ìˆ˜ì¹˜ ëª©í‘œ í¬í•¨)
- **RAG ê·¼ê±°**: [ë¬¸ì„œëª…]ì˜ (ë°ì´í„° ì¸ìš©)

### ì „ëµ 2: [ë³´ì¡° ì „ëµëª…]
- **ëª©í‘œ**: 2ìˆœìœ„ ë¬¸ì œ í•´ê²°
- **ì‹¤í–‰ ë°©ë²•**: 
  1. (ì‹¤í–‰ ë‹¨ê³„)
  2. (ì‹¤í–‰ ë‹¨ê³„)
- **ì˜ˆìƒ íš¨ê³¼**: (ì¸¡ì • ê°€ëŠ¥í•œ ëª©í‘œ)

---

## ğŸš€ 3. ì¦‰ì‹œ ì‹¤í–‰ ìº í˜ì¸ (2ê°œ)

### ìº í˜ì¸ 1: "ğŸ’ª [ìº í˜ì¸ëª…]!" 
- **ì‹¤í–‰ ê¸°ê°„**: (ì˜ˆ: 1ê°œì›”, 2ì£¼ ë“±)
- **íƒ€ê²Ÿ**: (êµ¬ì²´ì  ê³ ê°ì¸µ)
- **ì‹¤í–‰ ë‚´ìš©**: 
  - (êµ¬ì²´ì  ë°©ë²• 1)
  - (êµ¬ì²´ì  ë°©ë²• 2)
  - (í™ë³´ ì±„ë„)
- **ì˜ˆìƒ íš¨ê³¼**: {problem_name} ê°œì„  ëª©í‘œ (ìˆ˜ì¹˜)

### ìº í˜ì¸ 2: "ğŸ“¸ [ìº í˜ì¸ëª…]!"
- **ì‹¤í–‰ ê¸°ê°„**: 
- **íƒ€ê²Ÿ**: 
- **ì‹¤í–‰ ë‚´ìš©**: 
  - (ë°©ë²•)
  - (ë°©ë²•)
- **ì˜ˆìƒ íš¨ê³¼**: 

---

## ğŸ“Š 4. ê¸°ëŒ€ íš¨ê³¼ ìš”ì•½
- **{problem_name}** â†’ (ê°œì„  ëª©í‘œì¹˜, ì˜ˆ: 20% í–¥ìƒ)
- 2ìˆœìœ„ ë¬¸ì œ â†’ (ê°œì„  ëª©í‘œ)
- ì „ì²´ ë§¤ì¶œ ì˜í–¥ â†’ (ì˜ˆìƒ ìˆ˜ì¹˜)

**ì‘ì„± ì›ì¹™**: 
1. **ë¬¸ì œ ì§„ë‹¨**ì„ ê°€ì¥ ì•ì— ëª…í™•íˆ ì œì‹œ
2. ëª¨ë“  ì „ëµì€ **RAG ë¬¸ì„œ ë°ì´í„°ë¥¼ ê·¼ê±°**ë¡œ ì œì‹œ
3. **{industry} íŠ¹ì„±**ì„ ë°˜ì˜í•œ ì‹¤í–‰ ë°©ì•ˆ
4. **ì¸¡ì • ê°€ëŠ¥í•œ ëª©í‘œ** ì œì‹œ
5. ì´ëª¨ì§€ í™œìš©í•˜ì—¬ ê°€ë…ì„± í–¥ìƒ (ğŸ’°ğŸ“ˆğŸ¯ğŸ“Š)
"""
        
        try:
            response = self.gemini_model.generate_content(prompt)
            
            print("âœ… ì»¨ì„¤íŒ… ë‹µë³€ ìƒì„± ì™„ë£Œ!\n")
            print("=" * 80)
            print("ğŸ“‹ ì»¨ì„¤íŒ… ë‹µë³€")
            print("=" * 80)
            print()
            print(response.text)
            print()
            print("=" * 80)
            
            return response.text
            
        except Exception as e:
            print(f"âŒ Gemini API ì˜¤ë¥˜: {str(e)}")
            return None
    
    def save_response(self, modeling_data, relevant_docs, response, output_file="consulting_response.txt"):
        """ì»¨ì„¤íŒ… ë‹µë³€ ì €ì¥"""
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write("=" * 80 + "\n")
                f.write("ğŸ“‹ ìš”ì‹ì—… ê°€ë§¹ì  ë§ˆì¼€íŒ… ì»¨ì„¤íŒ… ë¦¬í¬íŠ¸\n")
                f.write("=" * 80 + "\n\n")
                
                # ë§¤ì¥ ì •ë³´
                f.write(f"ğŸ“ ë§¤ì¥ëª…: {modeling_data['store_name']}\n")
                f.write(f"ğŸ“ ì—…ì¢…: {modeling_data.get('industry', 'ìš”ì‹ì—…')}\n")
                f.write(f"ğŸ“ ìƒê¶Œ: {modeling_data['analysis']['market_type_context']}\n")
                f.write(f"ğŸ“… ìƒì„±ì¼: {pd.Timestamp.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M')}\n\n")
                
                # ì§„ë‹¨ ê²°ê³¼
                f.write("ğŸš¨ ì§„ë‹¨ ê²°ê³¼ (12ê°œ ë¬¸ì œ ìœ í˜• ë¶„ì„)\n")
                f.write("-" * 80 + "\n")
                for idx, issue in enumerate(modeling_data['analysis']['diagnosis_top3'], 1):
                    problem = issue['ì•½ì ']
                    severity = issue['ì‹¬ê°ë„']
                    solution = self.PROBLEM_TYPES.get(problem, "ë§ì¶¤ ì „ëµ í•„ìš”")
                    
                    if idx == 1:
                        f.write(f"\nğŸ”´ {idx}ìˆœìœ„ (ìµœìš°ì„ ): {problem}\n")
                    else:
                        f.write(f"\nğŸŸ  {idx}ìˆœìœ„: {problem}\n")
                    f.write(f"   - ì‹¬ê°ë„: {severity}/100\n")
                    f.write(f"   - ê¸°ë³¸ ì†”ë£¨ì…˜: {solution}\n")
                
                # RAG ì°¸ê³  ë¬¸ì„œ
                f.write("\n\nğŸ“š ì°¸ê³ í•œ ì™¸ì‹ì—… ë°ì´í„°\n")
                f.write("-" * 80 + "\n")
                for doc in relevant_docs:
                    f.write(f"  [{doc['similarity']:.1f}%] {doc['file_name']}\n")
                
                f.write("\n\n" + "=" * 80 + "\n\n")
                
                # AI ìƒì„± ì»¨ì„¤íŒ… ë‹µë³€
                f.write(response)
            
            print(f"\nğŸ“„ ì»¨ì„¤íŒ… ë‹µë³€ì´ '{output_file}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return True
            
        except Exception as e:
            print(f"âš ï¸  íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {str(e)}")
            return False


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # ========================================
    # ì„¤ì •: ì—¬ê¸°ë§Œ ìˆ˜ì •í•˜ì„¸ìš”!
    # ========================================
    
    # Gemini API í‚¤ (í•„ìˆ˜)
    GEMINI_API_KEY = "AIzaSyDTd6l7sR7LakKLHe9-6oN2DamBlBWyzAc"
    
    # RAG ë°ì´í„° í´ë” ê²½ë¡œ
    data_folder = r"C:\Temp\data\ragë°ì´í„°_ë³‘ì§„ë‹˜"
    
    # ë§¤ì¥ ì •ë³´ (ë¶„ì„í•  ë§¤ì¥ ë°ì´í„°)
    modeling_data = {
        "store_code": "00803E9174",
        "store_name": "ìš°ë™ëª…ê°€ ì™•ì‹­ë¦¬ì ",
        "industry": "ì¼ì‹ë‹¹",
        "status": "ì§„ë‹¨ ì™„ë£Œ",
        "analysis": {
            "type": "ì‹œê³„ì—´ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ì§„ë‹¨",
            "market_type_context": "ìš°ë™ë°€ì§‘í˜• ìƒê¶Œ (ê²½ìŸ ë§¤ì¥ 12ê°œ)",
            "diagnosis_top3": [
                {
                    "ì•½ì ": "ìƒê¶Œ ë‚´ ê²½ìŸ ì‹¬í™”",
                    "ì‹¬ê°ë„": 92
                },
                {
                    "ì•½ì ": "ê°ë‹¨ê°€ í•˜ë½",
                    "ì‹¬ê°ë„": 82
                },
                {
                    "ì•½ì ": "ë§¤ì¶œ ê·œëª¨ ê°ì†Œ",
                    "ì‹¬ê°ë„": 62
                }
            ]
        },
        "recommendations": [
            "ê²½ìŸì ê³¼ ì°¨ë³„í™”ë˜ëŠ” ìš°ë¦¬ ê°€ê²Œë§Œì˜ ì‹œê·¸ë‹ˆì²˜ ë©”ë‰´ ê°œë°œ",
            "ê°€ì¹˜ ìƒìŠ¹ì„ ìœ„í•œ ì„¸íŠ¸ ë©”ë‰´ ê°œë°œ ë˜ëŠ” ë©”ë‰´ ê³ ê¸‰í™”",
            "ë§¤ì¶œ ì¦ëŒ€ë¥¼ ìœ„í•œ í”¼í¬íƒ€ì„ ì„¸íŠ¸ ë©”ë‰´ ì¶œì‹œ ë˜ëŠ” ë°°ë‹¬ í™œì„±í™”"
        ]
    }
    
    # ========================================
    # ì‹¤í–‰ (ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì • ì•ˆ í•´ë„ ë¨)
    # ========================================
    
    print("\n" + "=" * 80)
    print("ğŸª RAG3 ì»¨ì„¤íŒ… ì‹œìŠ¤í…œ ì‹œì‘")
    print("=" * 80)
    
    # 1. ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    try:
        rag = RAG3ConsultingSystem(data_folder, GEMINI_API_KEY)
    except Exception as e:
        print(f"âŒ ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")
        return
    
    # 2. ë¬¸ì„œ ë¡œë“œ
    rag.load_documents()
    
    if len(rag.documents) == 0:
        print("\nâš ï¸  ë¬¸ì„œë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        print("í•´ê²° ë°©ë²•: pip install openpyxl")
        return
    
    # 3. ì„ë² ë”© ìƒì„±
    if not rag.build_embeddings():
        return
    
    # 4. ë§¤ì¥ ì •ë³´ ë° ì§„ë‹¨ ê²°ê³¼ ì¶œë ¥
    print("=" * 80)
    print("ğŸª ë§¤ì¥ ì •ë³´")
    print("=" * 80)
    print(f"ë§¤ì¥ëª…: {modeling_data['store_name']}")
    print(f"ì—…ì¢…: {modeling_data['industry']}")
    print(f"ìƒê¶Œ íŠ¹ì„±: {modeling_data['analysis']['market_type_context']}")
    
    print(f"\nğŸ“Š ì§„ë‹¨ ê²°ê³¼ (12ê°œ ë¬¸ì œ ìœ í˜• ì¤‘ ë°œê²¬ëœ ë¬¸ì œ):")
    for idx, issue in enumerate(modeling_data['analysis']['diagnosis_top3'], 1):
        problem = issue['ì•½ì ']
        severity = issue['ì‹¬ê°ë„']
        solution = RAG3ConsultingSystem.PROBLEM_TYPES.get(problem, "ë§ì¶¤ ì „ëµ í•„ìš”")
        
        if idx == 1:
            print(f"\n  ğŸ”´ {idx}ìˆœìœ„: {problem} (ì‹¬ê°ë„ {severity}/100) â­ ìµœìš°ì„ ")
        else:
            print(f"  ğŸŸ  {idx}ìˆœìœ„: {problem} (ì‹¬ê°ë„ {severity}/100)")
        print(f"      â†’ ê¸°ë³¸ ì†”ë£¨ì…˜: {solution}")
    
    print("\n" + "=" * 80 + "\n")
    
    # 5. RAG ë¬¸ì„œ ê²€ìƒ‰
    top_issue = modeling_data['analysis']['diagnosis_top3'][0]
    
    relevant_docs = rag.search_documents(
        problem_name=top_issue['ì•½ì '],
        industry=modeling_data['industry'],
        store_name=modeling_data['store_name'],
        market_context=modeling_data['analysis']['market_type_context'],
        top_k=2
    )
    
    if len(relevant_docs) == 0:
        print("âŒ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # 6. ì»¨ì„¤íŒ… ë‹µë³€ ìƒì„±
    response = rag.generate_consulting_response(modeling_data, relevant_docs)
    
    if not response:
        print("âŒ ì»¨ì„¤íŒ… ë‹µë³€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return
    
    # 7. ê²°ê³¼ ì €ì¥
    rag.save_response(modeling_data, relevant_docs, response)
    
    print("\n" + "=" * 80)
    print("âœ… ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("=" * 80 + "\n")


if __name__ == "__main__":
    main()
